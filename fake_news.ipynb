{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/muhammadalizaffar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muhammadalizaffar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/muhammadalizaffar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/muhammadalizaffar/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# NLTK for text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# For splitting the data and classic models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# For LSTM model using TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "      id                                              title  \\\n",
      "0   8476                       You Can Smell Hillary’s Fear   \n",
      "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4    875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "REAL    3171\n",
      "FAKE    3164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/muhammadalizaffar/Developers_hub/Task 3/fake_or_real_news.csv')\n",
    "\n",
    "# Preview the data\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned text preview:\n",
      "                                                text  \\\n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...   \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...   \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...   \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...   \n",
      "4  It's primary day in New York and front-runners...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  daniel greenfield shillman journal fellow free...  \n",
      "1  googl pinterest digg linkedin reddit stumbleup...  \n",
      "2  u secretari state john f kerri said monday sto...  \n",
      "3  — kayde king kaydeek novemb lesson tonight dem...  \n",
      "4  primari day new york frontrunn hillari clinton...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    # Apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Join tokens back to string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning to the text column\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "print(\"\\nCleaned text preview:\")\n",
    "print(df[['text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5068, Testing samples: 1267\n"
     ]
    }
   ],
   "source": [
    "X = df['cleaned_text']\n",
    "y = df['label']  # Assuming labels are \"FAKE\" and \"REAL\"\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes training complete.\n",
      "Random Forest training complete.\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes Pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "pipeline_nb.fit(X_train, y_train)\n",
    "print(\"Naïve Bayes training complete.\")\n",
    "\n",
    "# Random Forest Pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "print(\"Random Forest training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.8903\n",
      "Naïve Bayes F1 Score: 0.8901\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.88      0.90      0.89       628\n",
      "        REAL       0.90      0.88      0.89       639\n",
      "\n",
      "    accuracy                           0.89      1267\n",
      "   macro avg       0.89      0.89      0.89      1267\n",
      "weighted avg       0.89      0.89      0.89      1267\n",
      "\n",
      "--------------------------------------------------\n",
      "Random Forest Accuracy: 0.9187\n",
      "Random Forest F1 Score: 0.9184\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.91      0.93      0.92       628\n",
      "        REAL       0.93      0.91      0.92       639\n",
      "\n",
      "    accuracy                           0.92      1267\n",
      "   macro avg       0.92      0.92      0.92      1267\n",
      "weighted avg       0.92      0.92      0.92      1267\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='REAL')\n",
    "    print(f\"{model_name} Accuracy: {acc:.4f}\")\n",
    "    print(f\"{model_name} F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "evaluate_model(pipeline_nb, X_test, y_test, \"Naïve Bayes\")\n",
    "evaluate_model(pipeline_rf, X_test, y_test, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadalizaffar/Developers_hub/Task 3/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - accuracy: 0.6346 - loss: 0.6534 - val_accuracy: 0.7998 - val_loss: 0.5064\n",
      "Epoch 2/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - accuracy: 0.8549 - loss: 0.4243 - val_accuracy: 0.8432 - val_loss: 0.3473\n",
      "Epoch 3/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.8914 - loss: 0.2794 - val_accuracy: 0.8679 - val_loss: 0.3031\n",
      "Epoch 4/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.9411 - loss: 0.1769 - val_accuracy: 0.8787 - val_loss: 0.3106\n",
      "Epoch 5/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - accuracy: 0.9568 - loss: 0.1334 - val_accuracy: 0.8639 - val_loss: 0.3205\n",
      "Epoch 6/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.9686 - loss: 0.0990 - val_accuracy: 0.8649 - val_loss: 0.3594\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Parameters for tokenization and padding\n",
    "max_features = 5000\n",
    "max_len = 150  # maximum length of sequences\n",
    "embedding_dim = 50\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Build the LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(max_features, embedding_dim, input_length=max_len))\n",
    "model_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()\n",
    "\n",
    "# Convert labels to binary (assume \"REAL\"=1, \"FAKE\"=0)\n",
    "y_train_bin = y_train.apply(lambda x: 1 if x == 'REAL' else 0).values\n",
    "y_test_bin = y_test.apply(lambda x: 1 if x == 'REAL' else 0).values\n",
    "\n",
    "# Train LSTM with EarlyStopping to prevent overfitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "history = model_lstm.fit(X_train_pad, y_train_bin, \n",
    "                         epochs=10, batch_size=64, \n",
    "                         validation_split=0.2, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8719 - loss: 0.3685\n",
      "LSTM Accuracy: 0.8769\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       628\n",
      "           1       0.87      0.89      0.88       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the LSTM model\n",
    "loss, accuracy = model_lstm.evaluate(X_test_pad, y_test_bin)\n",
    "print(f\"LSTM Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally, you can print predictions for a few samples:\n",
    "y_pred_lstm = (model_lstm.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_bin, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save classical models\n",
    "joblib.dump(pipeline_nb, 'fake_news_nb.pkl')\n",
    "joblib.dump(pipeline_rf, 'fake_news_rf.pkl')\n",
    "\n",
    "# Save the tokenizer and LSTM model\n",
    "joblib.dump(tokenizer, 'tokenizer.pkl')\n",
    "model_lstm.save('fake_news_lstm.h5')\n",
    "\n",
    "print(\"Models and tokenizer saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
